{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "- A running instance of a computer program\n",
    "\n",
    "## 1. Processes vs Threads\n",
    "- Process: Sidesteps GIL, Less need for synchronization, Can be paused and terminated, more resilient\n",
    "- Thread: Higher memory footprint, expensive content switches\n",
    "\n",
    "## 2. Simple multiprocessing pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing some work in thread\n",
      "Start thread, process alive: True\n",
      "echo: text\n",
      "End thread\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def do_some_work(val):\n",
    "    print(\"Doing some work in thread\")\n",
    "    time.sleep(1)\n",
    "    print(\"echo: {}\".format(val))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    val = \"text\"\n",
    "    p = multiprocessing.Process(target=do_some_work, args=(val,))\n",
    "    p.start()\n",
    "    print(\"Start thread, process alive: {}\".format(p.is_alive()))\n",
    "#     p.terminate()  # Terminate the process\n",
    "    p.join()\n",
    "    print(\"End thread\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Terms \n",
    "- Pickle: Process whereby a Python object hierarchy is converted into a byte stream. \"Unpickling\" is the inverse operation.\n",
    "- Deamon Process: A child process that does not prevent its parent process from exiting\n",
    "\n",
    "## 4. Other operation\n",
    "- p.is_alive(): Check if process is alive\n",
    "- p.terminate(): Terminate a process\n",
    "- multiprocessing.cpu_count(): Check # of CPUs\n",
    "\n",
    "## 5. Process pool\n",
    "- A process pool object which controls a pool of worker processes to which jobs can be submitted. It supports asynchronous results with timeouts and callbacks and has a parallel map implementation.\n",
    "\n",
    "### 5.0. Pool example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ForkPoolWorker-2\n",
      "Start ForkPoolWorker-3\n",
      "Start ForkPoolWorker-4\n",
      "Start ForkPoolWorker-5\n",
      "Start ForkPoolWorker-6\n",
      "Start ForkPoolWorker-7\n",
      "Start ForkPoolWorker-8\n",
      "Start ForkPoolWorker-9\n",
      "Outputs: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "def do_work(data):\n",
    "    time.sleep(1)\n",
    "    return data**2\n",
    "\n",
    "def start_process():\n",
    "    print(\"Start\", multiprocessing.current_process().name)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    pool_size = multiprocessing.cpu_count() * 2\n",
    "    pool = multiprocessing.Pool(processes=pool_size, initializer=start_process)\n",
    "    inputs = list(range(10))\n",
    "    # map(): block until it's ready\n",
    "    # map_async(): non-block and return a call back\n",
    "    #              use .get() on call back object to get result\n",
    "    outputs = pool.map(do_work, inputs)  \n",
    "    pool.close()  # No more task accepted\n",
    "    pool.join()  # Wait for the worker processes to exit\n",
    "    print(\"Outputs:\", outputs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inter-process Communication\n",
    "### 6.0. Pipe\n",
    "- Communication between process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HiHiHiHi\n",
      "HiHiHiHi\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from multiprocessing import Pipe, Process\n",
    "import time\n",
    "\n",
    "def make_tuple(conn):\n",
    "    num = random.randint(1, 9)\n",
    "    conn.send((\"Hi\", num))\n",
    "    print(conn.recv())\n",
    "    \n",
    "    \n",
    "def make_string(conn):\n",
    "    tup = conn.recv()\n",
    "    result = \"\"\n",
    "    substr, num = tup\n",
    "    for _ in range(num):\n",
    "        result += substr\n",
    "    print(result)\n",
    "    conn.send(result)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    conn1, conn2 = Pipe(duplex=True)\n",
    "    p1 = Process(target=make_tuple, args=(conn1,))\n",
    "    p2 = Process(target=make_string, args=(conn2,))\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Queue\n",
    "- Pipe can only have two endpoints\n",
    "- Queue can have multiple producers and consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HiHiHiHiHiHiHiHiHi\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Data flow\n",
    "1. make_tuple -> (\"Hi\", num) -> make_string\n",
    "2. sleep for 1 second\n",
    "3. make_string -> result -> make_tuple\n",
    "4. make_tuple print result by using queue.get()\n",
    "\"\"\"\n",
    "from multiprocessing import Queue\n",
    "\n",
    "def make_tuple(queue):\n",
    "    num = random.randint(1, 9)\n",
    "    queue.put((\"Hi\", num))\n",
    "    time.sleep(1)\n",
    "    print(queue.get()) # Get from 'make_string'\n",
    "        \n",
    "def make_string(queue):\n",
    "    tup = queue.get()\n",
    "    result = \"\"\n",
    "    substr, num = tup\n",
    "    for _ in range(num):\n",
    "        result += substr\n",
    "    queue.put(result)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    queue = Queue()\n",
    "    p1 = Process(target=make_tuple, args=(queue,))\n",
    "    p2 = Process(target=make_string, args=(queue,))\n",
    "    p1.start()\n",
    "    p2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sharing State Between Processes\n",
    "### 7.0. Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value\n",
    "import multiprocessing\n",
    "import ctypes\n",
    "\n",
    "counter = Value('i')  # shared object of type int, defaults to 0\n",
    "# shared object of type boolean, defaulting to False, unsynchronized\n",
    "is_running = Value(ctypes.c_bool, False, lock=False)  \n",
    "\n",
    "my_lock = multiprocessing.Lock()\n",
    "# Shared object of type long, with a lock specified\n",
    "size_counter = Value('l', 0, lock=my_lock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Manager\n",
    "- Share variables between processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {0: 0, 1: 1, 2: 4, 4: 16, 3: 9, 6: 36, 5: 25, 7: 49}\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "\n",
    "def do_work(dictionary, item):\n",
    "    dictionary[item] = item ** 2\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    mgr = multiprocessing.Manager()\n",
    "    d = mgr.dict()  # Shared dict\n",
    "    # Multiple processes work on same shared-dict\n",
    "    jobs = [\n",
    "        Process(target=do_work, args=(d, i)) for i in range(8)\n",
    "    ]\n",
    "\n",
    "    for j in jobs:\n",
    "        j.start()\n",
    "\n",
    "    for j in jobs:\n",
    "        j.join()\n",
    "\n",
    "    print(\"Results:\", d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
